{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0.post4'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import h5py\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from heapq import nlargest\n",
    "import dill\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FEATURES = \"./images/IR_image_features.h5\"\n",
    "IMG_ID = \"./images/IR_img_features2id.json\"\n",
    "\n",
    "TRAIN_HARD = \"./Data/Hard/IR_train_hard.json\"\n",
    "TRAIN_EASY = \"./Data/Easy/IR_train_easy.json\"\n",
    "TEST_HARD = \"./Data/Hard/IR_test_hard.json\"\n",
    "TEST_EASY = \"./Data/Easy/IR_test_easy.json\"\n",
    "VAL_HARD = \"./Data/Hard/IR_val_hard.json\"\n",
    "VAL_EASY = \"./Data/Easy/IR_val_easy.json\"\n",
    "IMGID2IMGINFO = \"./Data/imgid2imginfo.json\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "CAPTION_DICT = {}\n",
    "CURRENT_MODEL_NAME = \"LSTM_HARD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(x, name):\n",
    "    import pickle\n",
    "    file_name = './results/' + CURRENT_MODEL_NAME + '/' + name + '.npy'\n",
    "    np.save(file_name, np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET features from images\n",
    "with open(\"./images/IR_img_features2id.json\", 'r') as f:\n",
    "    visual_feat_mapping = json.load(f)['IR_imgid2id']\n",
    "f.close()\n",
    "\n",
    "img_features = np.asarray( h5py.File(\"./images/IR_image_features.h5\", 'r')['img_features'])\n",
    "\n",
    "def get_feature_from_id(img_id):\n",
    "    h5_id = visual_feat_mapping[str(img_id)]\n",
    "    return img_features[h5_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-49-b0ba592f3fd4>\", line 44, in show_img_from_id\n",
      "    draw.multiline_text((10, 10), CAPTION_DICT[target_id].replace(\"?\", \"?\") ,(0,0,0), font=fnt)\n",
      "KeyError: 378466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Helper function to show an image, from a image id \"\"\"\n",
    "#source: https://stackoverflow.com/questions/34255938/is-there-a-way-to-specify-the-width-of-a-rectangle-in-pil\n",
    "def draw_rectangle(draw, coordinates, color, width=100):\n",
    "    for i in range(width):\n",
    "        rect_start = (coordinates[0][0] - i, coordinates[0][1] - i)\n",
    "        rect_end = (coordinates[1][0] + i, coordinates[1][1] + i)\n",
    "        draw.rectangle((rect_start, rect_end), outline = color)\n",
    "\n",
    "def show_img_from_id(img_ids, target_id = -1):\n",
    "    \n",
    "    try:\n",
    "        with open(IMGID2IMGINFO, 'r') as f:\n",
    "            imgid2info = json.load(f)\n",
    "\n",
    "        response = requests.get(imgid2info[str(img_ids[0])]['coco_url'])\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        imgs = [img, img]\n",
    "        width, height = img.size\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        line_width = 30\n",
    "        draw.rectangle(((0, 0), (width*2, height*2)), fill=\"white\")\n",
    "        for img_id in img_ids:\n",
    "            response = requests.get(imgid2info[str(img_id)]['coco_url'])\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            if(img_id == target_id):\n",
    "                width, height = img.size\n",
    "                draw = ImageDraw.Draw(img)\n",
    "                line_width = 30\n",
    "                draw_rectangle(draw, coordinates=((line_width, line_width), (width - line_width, height - line_width)), color=\"green\", width=line_width)\n",
    "            imgs.append(img)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[-1][1]\n",
    "        imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "        # save that beautiful picture\n",
    "        imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "        width, height = imgs_comb.size\n",
    "        draw = ImageDraw.Draw(imgs_comb)\n",
    "        if(target_id != -1):\n",
    "            # fnt = ImageFont.truetype(\"/Library/Fonts/Comic Sans MS.ttf\", 30) \n",
    "            fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 30)\n",
    "            draw.multiline_text((10, 10), CAPTION_DICT[target_id].replace(\"?\", \"?\") ,(0,0,0), font=fnt)\n",
    "\n",
    "        files = \"[\"+str(target_id)+\"]_\"\n",
    "        files += '_'.join(map(str, img_ids))\n",
    "        if(img_ids[0] == target_id):\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/correct/top1/'\n",
    "        elif(img_ids[1] == target_id or img_ids[2] == target_id or img_ids[3] == target_id or img_ids[4] == target_id):\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/correct/top5/'  \n",
    "        else:\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/wrong/' \n",
    "        imgs_comb.save( file_name + files + '.jpg' )\n",
    "    except:\n",
    "        import traceback\n",
    "        print( traceback.format_exc())\n",
    "        pass\n",
    "    \n",
    "show_img_from_id([378466, 378466, 378466, 378466], 378466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    \n",
    "    ax.plot(top5_val_list, label='top5 validation', c='darkred')\n",
    "    ax.plot(top5_train_list, label='top5 train', c='royalblue')\n",
    "    \n",
    "    ax.plot(top1_val_list, linestyle=':', label='top1 validation', c='darkred')\n",
    "    ax.plot(top1_train_list, linestyle=':', label='top1 train', c='royalblue')\n",
    "    \n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.75, box.height])\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title('Learning curve of LSTM Easy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.savefig('./results/' + CURRENT_MODEL_NAME + '/accuracy1.png')\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess a sentence\n",
    "\"\"\"\n",
    "def preprocess(sentence, stemmer, stop):\n",
    "    low_sent = sentence.lower()\n",
    "    # Possibility to tokenize entire dataset and put in counter to filter out\n",
    "    # infrequent/frequent words\n",
    "    tok_sent = word_tokenize(low_sent)\n",
    "    stop_stem_sent = [stemmer.stem(i) for i in tok_sent if i not in stop]\n",
    "    return stop_stem_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert Samples\n",
    "\"\"\"\n",
    "\n",
    "def get_dialog_caption_targets_from_sample(sample):\n",
    "    dialog = ''\n",
    "    caption = sample['caption']\n",
    "    targets = []\n",
    "    targetidx = sample['target']\n",
    "   \n",
    "    dialog_text = ''\n",
    "    for d in sample['dialog']:\n",
    "        dialog += ' ' + d[0]\n",
    "        dialog_text += ' ' + d[0] + '\\n'\n",
    "\n",
    "    for img in sample['img_list']:\n",
    "        targets.append(img)\n",
    "    \n",
    "    CAPTION_DICT[targets[targetidx]] = dialog_text + \"  \\n \" + caption\n",
    "    return dialog, caption, targets, targetidx\n",
    "\n",
    "Sample = namedtuple(\"Sample\", [\"words\", \"images\", \"target\"])\n",
    "\n",
    "\"\"\"\n",
    " For every Sample we retrieve the sentences and the img_ids, and the correct target_id. \n",
    "\"\"\"\n",
    "def read_dataset(filename, stemmer, stopwords):\n",
    "    with open(filename, \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "    f.close()\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        if(idx % 10000 == 0):\n",
    "            print(idx)\n",
    "        dialog, caption, targets, targetidx = get_dialog_caption_targets_from_sample(dataset[\n",
    "                                                                                     str(sample)])\n",
    "        sentences = preprocess(dialog + ' ' + caption, stemmer, stopwords)\n",
    "        yield Sample(words=[w2i[x] for x in sentences], images=targets, target=targetidx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "UNK = w2i[\"<UNK>\"]\n",
    "PAD = w2i[\"<PAD>\"]\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop = stopwords.words('english') + list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#read the datasets and use w2i (only do this once)\n",
    "train = list(read_dataset(TRAIN_HARD, stemmer, stop))\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "val = list(read_dataset(VAL_HARD, stemmer, stop))\n",
    "test = list(read_dataset(TEST_HARD, stemmer, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CLASS LSTM \n",
    "\"\"\"\n",
    "class LSTMC3(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, img_feat_dim, hidden_dim_mlp, hidden_dim_lstm, num_layers_lstm,  output_dim, batch_size):\n",
    "        super(LSTMC3, self).__init__()\n",
    "        \n",
    "\n",
    "\n",
    "class LSTMC2(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, img_feat_dim, hidden_dim_mlp, hidden_dim_lstm, num_layers_lstm,  output_dim, batch_size):\n",
    "        super(LSTMC2, self).__init__()\n",
    "        self.hidden_dim = hidden_dim_lstm\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx = PAD)\n",
    "        #\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim_lstm,batch_first=True)\n",
    "        self.linear1 = nn.Linear(hidden_dim_lstm+img_feat_dim, hidden_dim_mlp)\n",
    "        self.linear2 = nn.Linear(hidden_dim_mlp, output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if CUDA:\n",
    "            return Variable(torch.cuda.FloatTensor(1, self.batch_size, self.hidden_dim).fill_(0)),  Variable(torch.cuda.FloatTensor(1, self.batch_size, self.hidden_dim).fill_(0))\n",
    "        else:\n",
    "            return (Variable(torch.zeros(1, self.batch_size, self.hidden_dim)), Variable(torch.zeros(1, self.batch_size, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence, image_feat, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "\n",
    "        h = torch.gather(lstm_out,1,lengths.view(-1,1,1).expand(len(lengths),1,self.hidden_dim)-1).repeat(1,10,1)\n",
    "        #Size lstm_out = 99 x 75 x 300\n",
    "\n",
    "        #100x10x300\n",
    "        lin1 = torch.cat((h,image_feat),2)\n",
    "        lin1 = self.linear1(lin1)\n",
    "        lin1 = F.relu(lin1)\n",
    "        lin2 = self.linear2(lin1)\n",
    "        return lin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:  100 LEARNING_RATE:  0.001\n",
      "\n",
      "LSTMC2(\n",
      "  (word_embeddings): Embedding(15456, 300, padding_idx=1)\n",
      "  (lstm): LSTM(300, 100, batch_first=True)\n",
      "  (linear1): Linear(in_features=2148, out_features=45)\n",
      "  (linear2): Linear(in_features=45, out_features=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# INIT MODEL AND INIT OPTIMIZER\n",
    "print(\"Batch_size: \", BATCH_SIZE, \"LEARNING_RATE: \",LEARNING_RATE)\n",
    "print()\n",
    "\n",
    "model = LSTMC2(nwords, 300, 2048, 45, 100, 1, 1, BATCH_SIZE)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "print(model)\n",
    "\n",
    "#@TODO we can use a adaptive learnrate for adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HELPER FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "def preprocessbatch(batch):\n",
    "    \"\"\" Add zero-padding to a batch. \"\"\"\n",
    "    seqs = [sample.words for sample in batch]\n",
    "    \n",
    "    lengths = [len(sample.words) for sample in batch]\n",
    "    \n",
    "    max_length = max(map(len, seqs))\n",
    "    seqs = [seq + [PAD] * (max_length - len(seq)) for seq in seqs]\n",
    "\n",
    "    ims = np.array([[get_feature_from_id(img_id) for img_id in sample.images] for sample in batch])\n",
    "\n",
    "    idxs = [sample.target for sample in batch]\n",
    "    \n",
    "    image_ids = [sample.images for sample in batch]\n",
    "\n",
    "    return seqs, ims, idxs, image_ids, lengths\n",
    "\n",
    "def minibatch(data, batch_size=BATCH_SIZE):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i+batch_size]\n",
    "\n",
    "def getLongTensor(x):\n",
    "    tensor = torch.cuda.LongTensor(torch.from_numpy(\n",
    "        x).cuda()) if CUDA else torch.LongTensor(x)\n",
    "    return Variable(tensor)\n",
    "\n",
    "def getFloatTensor(x):\n",
    "    tensor = torch.cuda.FloatTensor(torch.from_numpy(\n",
    "        x).cuda()) if CUDA else torch.FloatTensor(x)\n",
    "    return Variable(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "FUNCTIONS TO SEE HOW GOOD OUR MODEL DID\n",
    "\n",
    "@TODO: Not fast \n",
    "@TODO: top 5 currently not implemented\n",
    "\"\"\"\n",
    "def evaluate(model, data, show_n_wrong_images  = 0, show_n_good_images=0):\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    \n",
    "    counter_good = 0\n",
    "    counter_wrong = 0\n",
    "    for batch in minibatch(data):\n",
    "        seqs, image_features, idxs, image_ids, lengths = preprocessbatch(batch)\n",
    "        scores = model(getLongTensor(np.array([seqs]))[0], getFloatTensor(image_features), getLongTensor(np.array(lengths)))\n",
    "        targets = getLongTensor(np.array([idxs]))\n",
    "        _, predictions = torch.max(scores[:, :,0].data, 1)\n",
    "        \n",
    "        \n",
    "        _, top5_predictions = torch.topk(scores[:, :,0].data, 5, largest=True, sorted=True)\n",
    "        _, top10_predictions = torch.topk(scores[:, :,0].data, 10, largest=True, sorted=True)\n",
    "\n",
    "        for i in range(len(top5_predictions)):\n",
    "            if((targets[0][i].data.cpu().numpy() if CUDA else targets[0][i].data.numpy()) in (top5_predictions[i].cpu().numpy() if CUDA else top5_predictions[i].numpy())):\n",
    "                idx, = np.where((targets[0][i].data.cpu().numpy() if CUDA else targets[0][i].data.numpy()) == (top5_predictions[i].cpu().numpy() if CUDA else top5_predictions[i].numpy()))\n",
    "                if idx == 0:\n",
    "                    top1 += 1\n",
    "                \n",
    "                top5 += 1\n",
    "                \n",
    "                #Show the images Good examples\n",
    "                if counter_good < show_n_good_images:\n",
    "                    image_list = list(np.array(image_ids[i])[(top10_predictions[i].cpu().numpy() if CUDA else top10_predictions[i].numpy())])\n",
    "                    show_img_from_id(image_list, target_id = int(np.array(image_ids[i])[idxs[i]]))\n",
    "                    counter_good += 1\n",
    "            else: \n",
    "                #Show the images Bad examples\n",
    "                if counter_wrong < show_n_wrong_images:\n",
    "                    image_list = list(np.array(image_ids[i])[(top10_predictions[i].cpu().numpy() if CUDA else top10_predictions[i].numpy())])\n",
    "                    show_img_from_id(image_list, target_id = int(np.array(image_ids[i])[idxs[i]]))\n",
    "                    counter_wrong += 1\n",
    "           \n",
    "    return top1/len(data), top5/len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: avg train loss=2.2186, time=4.43s\n",
      "VALIDATION: TOP 1: 0.1494, TOP 5: 0.6664\n",
      "iter 1: avg train loss=2.0396, time=4.43s\n",
      "VALIDATION: TOP 1: 0.185, TOP 5: 0.7256\n",
      "iter 2: avg train loss=1.9483, time=4.42s\n",
      "VALIDATION: TOP 1: 0.2142, TOP 5: 0.7706\n",
      "iter 3: avg train loss=1.8700, time=4.55s\n",
      "VALIDATION: TOP 1: 0.2318, TOP 5: 0.7924\n",
      "iter 4: avg train loss=1.7789, time=4.37s\n",
      "VALIDATION: TOP 1: 0.2562, TOP 5: 0.7904\n",
      "iter 5: avg train loss=1.6757, time=4.81s\n",
      "VALIDATION: TOP 1: 0.264, TOP 5: 0.7942\n",
      "iter 6: avg train loss=1.5732, time=4.87s\n",
      "VALIDATION: TOP 1: 0.2692, TOP 5: 0.8086\n",
      "iter 7: avg train loss=1.4656, time=4.50s\n",
      "VALIDATION: TOP 1: 0.2854, TOP 5: 0.8174\n",
      "iter 8: avg train loss=1.3600, time=4.58s\n",
      "VALIDATION: TOP 1: 0.276, TOP 5: 0.8162\n",
      "iter 9: avg train loss=1.2628, time=4.63s\n",
      "VALIDATION: TOP 1: 0.2922, TOP 5: 0.8238\n",
      "iter 10: avg train loss=1.1573, time=4.50s\n",
      "VALIDATION: TOP 1: 0.281, TOP 5: 0.8026\n",
      "iter 11: avg train loss=1.0661, time=4.49s\n",
      "VALIDATION: TOP 1: 0.296, TOP 5: 0.8284\n",
      "iter 12: avg train loss=0.9792, time=4.55s\n",
      "VALIDATION: TOP 1: 0.2934, TOP 5: 0.826\n",
      "iter 13: avg train loss=0.8978, time=4.46s\n",
      "VALIDATION: TOP 1: 0.2892, TOP 5: 0.8208\n",
      "iter 14: avg train loss=0.8216, time=4.44s\n",
      "VALIDATION: TOP 1: 0.297, TOP 5: 0.8276\n",
      "iter 15: avg train loss=0.7547, time=4.60s\n",
      "VALIDATION: TOP 1: 0.3002, TOP 5: 0.8244\n",
      "iter 16: avg train loss=0.6986, time=4.53s\n",
      "VALIDATION: TOP 1: 0.3036, TOP 5: 0.8324\n",
      "iter 17: avg train loss=0.6367, time=4.52s\n",
      "VALIDATION: TOP 1: 0.2918, TOP 5: 0.8312\n",
      "iter 18: avg train loss=0.5863, time=4.77s\n",
      "VALIDATION: TOP 1: 0.3046, TOP 5: 0.8208\n",
      "iter 19: avg train loss=0.5412, time=4.69s\n",
      "VALIDATION: TOP 1: 0.2946, TOP 5: 0.8222\n",
      "iter 20: avg train loss=0.5086, time=4.57s\n",
      "VALIDATION: TOP 1: 0.3034, TOP 5: 0.8308\n",
      "iter 21: avg train loss=0.4713, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3012, TOP 5: 0.83\n",
      "iter 22: avg train loss=0.4278, time=4.53s\n",
      "VALIDATION: TOP 1: 0.3036, TOP 5: 0.828\n",
      "iter 23: avg train loss=0.4081, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3052, TOP 5: 0.8284\n",
      "iter 24: avg train loss=0.3845, time=4.40s\n",
      "VALIDATION: TOP 1: 0.3006, TOP 5: 0.823\n",
      "iter 25: avg train loss=0.3560, time=4.48s\n",
      "VALIDATION: TOP 1: 0.3034, TOP 5: 0.8364\n",
      "iter 26: avg train loss=0.3553, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3084, TOP 5: 0.8362\n",
      "iter 27: avg train loss=0.3295, time=4.40s\n",
      "VALIDATION: TOP 1: 0.2938, TOP 5: 0.8158\n",
      "iter 28: avg train loss=0.2977, time=4.48s\n",
      "VALIDATION: TOP 1: 0.308, TOP 5: 0.8332\n",
      "iter 29: avg train loss=0.2742, time=4.52s\n",
      "VALIDATION: TOP 1: 0.3074, TOP 5: 0.8272\n",
      "iter 30: avg train loss=0.2807, time=4.41s\n",
      "VALIDATION: TOP 1: 0.3054, TOP 5: 0.8292\n",
      "iter 31: avg train loss=0.2788, time=4.57s\n",
      "VALIDATION: TOP 1: 0.3024, TOP 5: 0.8296\n",
      "iter 32: avg train loss=0.2548, time=4.64s\n",
      "VALIDATION: TOP 1: 0.3028, TOP 5: 0.8334\n",
      "iter 33: avg train loss=0.2538, time=4.55s\n",
      "VALIDATION: TOP 1: 0.2988, TOP 5: 0.83\n",
      "iter 34: avg train loss=0.2426, time=4.70s\n",
      "VALIDATION: TOP 1: 0.2996, TOP 5: 0.829\n",
      "iter 35: avg train loss=0.2102, time=4.45s\n",
      "VALIDATION: TOP 1: 0.3044, TOP 5: 0.8326\n",
      "iter 36: avg train loss=0.1913, time=4.48s\n",
      "VALIDATION: TOP 1: 0.2956, TOP 5: 0.83\n",
      "iter 37: avg train loss=0.2046, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3022, TOP 5: 0.8304\n",
      "iter 38: avg train loss=0.2153, time=4.57s\n",
      "VALIDATION: TOP 1: 0.3028, TOP 5: 0.8314\n",
      "iter 39: avg train loss=0.2082, time=4.53s\n",
      "VALIDATION: TOP 1: 0.3162, TOP 5: 0.8324\n",
      "iter 40: avg train loss=0.1855, time=4.50s\n",
      "VALIDATION: TOP 1: 0.3082, TOP 5: 0.8372\n",
      "iter 41: avg train loss=0.1985, time=4.52s\n",
      "VALIDATION: TOP 1: 0.3066, TOP 5: 0.8322\n",
      "iter 42: avg train loss=0.1878, time=4.48s\n",
      "VALIDATION: TOP 1: 0.3092, TOP 5: 0.8402\n",
      "iter 43: avg train loss=0.1800, time=4.60s\n",
      "VALIDATION: TOP 1: 0.3028, TOP 5: 0.8344\n",
      "iter 44: avg train loss=0.1680, time=4.50s\n",
      "VALIDATION: TOP 1: 0.313, TOP 5: 0.8372\n",
      "iter 45: avg train loss=0.1462, time=4.63s\n",
      "VALIDATION: TOP 1: 0.3058, TOP 5: 0.8384\n",
      "iter 46: avg train loss=0.1951, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3106, TOP 5: 0.8326\n",
      "iter 47: avg train loss=0.1722, time=4.70s\n",
      "VALIDATION: TOP 1: 0.3082, TOP 5: 0.8378\n",
      "iter 48: avg train loss=0.1485, time=4.53s\n",
      "VALIDATION: TOP 1: 0.3096, TOP 5: 0.8268\n",
      "iter 49: avg train loss=0.1420, time=4.67s\n",
      "VALIDATION: TOP 1: 0.308, TOP 5: 0.8276\n",
      "iter 50: avg train loss=0.1391, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3092, TOP 5: 0.838\n",
      "iter 51: avg train loss=0.1635, time=4.37s\n",
      "VALIDATION: TOP 1: 0.315, TOP 5: 0.8336\n",
      "iter 52: avg train loss=0.2005, time=4.39s\n",
      "VALIDATION: TOP 1: 0.3042, TOP 5: 0.8276\n",
      "iter 53: avg train loss=0.1822, time=4.37s\n",
      "VALIDATION: TOP 1: 0.3056, TOP 5: 0.8274\n",
      "iter 54: avg train loss=0.1356, time=4.41s\n",
      "VALIDATION: TOP 1: 0.3102, TOP 5: 0.8302\n",
      "iter 55: avg train loss=0.1065, time=4.36s\n",
      "VALIDATION: TOP 1: 0.301, TOP 5: 0.832\n",
      "iter 56: avg train loss=0.1020, time=4.42s\n",
      "VALIDATION: TOP 1: 0.3142, TOP 5: 0.8346\n",
      "iter 57: avg train loss=0.1145, time=4.44s\n",
      "VALIDATION: TOP 1: 0.313, TOP 5: 0.8378\n",
      "iter 58: avg train loss=0.1509, time=4.39s\n",
      "VALIDATION: TOP 1: 0.3098, TOP 5: 0.8358\n",
      "iter 59: avg train loss=0.1738, time=4.43s\n",
      "VALIDATION: TOP 1: 0.3206, TOP 5: 0.8414\n",
      "iter 60: avg train loss=0.1605, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3144, TOP 5: 0.8404\n",
      "iter 61: avg train loss=0.1364, time=4.46s\n",
      "VALIDATION: TOP 1: 0.3122, TOP 5: 0.8376\n",
      "iter 62: avg train loss=0.1079, time=4.48s\n",
      "VALIDATION: TOP 1: 0.312, TOP 5: 0.8418\n",
      "iter 63: avg train loss=0.0921, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3178, TOP 5: 0.8414\n",
      "iter 64: avg train loss=0.1011, time=4.52s\n",
      "VALIDATION: TOP 1: 0.3094, TOP 5: 0.8382\n",
      "iter 65: avg train loss=0.1236, time=4.45s\n",
      "VALIDATION: TOP 1: 0.3228, TOP 5: 0.8416\n",
      "iter 66: avg train loss=0.1592, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3192, TOP 5: 0.8394\n",
      "iter 67: avg train loss=0.1481, time=4.46s\n",
      "VALIDATION: TOP 1: 0.3086, TOP 5: 0.834\n",
      "iter 68: avg train loss=0.1395, time=4.38s\n",
      "VALIDATION: TOP 1: 0.3138, TOP 5: 0.841\n",
      "iter 69: avg train loss=0.1137, time=4.37s\n",
      "VALIDATION: TOP 1: 0.3126, TOP 5: 0.8288\n",
      "iter 70: avg train loss=0.0921, time=4.39s\n",
      "VALIDATION: TOP 1: 0.3062, TOP 5: 0.8372\n",
      "iter 71: avg train loss=0.0877, time=4.43s\n",
      "VALIDATION: TOP 1: 0.3124, TOP 5: 0.8404\n",
      "iter 72: avg train loss=0.0970, time=4.37s\n",
      "VALIDATION: TOP 1: 0.3114, TOP 5: 0.8412\n",
      "iter 73: avg train loss=0.1057, time=4.43s\n",
      "VALIDATION: TOP 1: 0.3194, TOP 5: 0.8388\n",
      "iter 74: avg train loss=0.1078, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3198, TOP 5: 0.8364\n",
      "iter 75: avg train loss=0.1361, time=4.40s\n",
      "VALIDATION: TOP 1: 0.3044, TOP 5: 0.8252\n",
      "iter 76: avg train loss=0.1394, time=4.41s\n",
      "VALIDATION: TOP 1: 0.313, TOP 5: 0.8422\n",
      "iter 77: avg train loss=0.1225, time=4.54s\n",
      "VALIDATION: TOP 1: 0.3104, TOP 5: 0.84\n",
      "iter 78: avg train loss=0.1175, time=4.39s\n",
      "VALIDATION: TOP 1: 0.3092, TOP 5: 0.8368\n",
      "iter 79: avg train loss=0.0889, time=4.42s\n",
      "VALIDATION: TOP 1: 0.3094, TOP 5: 0.8334\n",
      "iter 80: avg train loss=0.0858, time=4.41s\n",
      "VALIDATION: TOP 1: 0.3042, TOP 5: 0.831\n",
      "iter 81: avg train loss=0.1002, time=4.40s\n",
      "VALIDATION: TOP 1: 0.3164, TOP 5: 0.8324\n",
      "iter 82: avg train loss=0.1422, time=4.41s\n",
      "VALIDATION: TOP 1: 0.3142, TOP 5: 0.835\n",
      "iter 83: avg train loss=0.1048, time=4.46s\n",
      "VALIDATION: TOP 1: 0.3194, TOP 5: 0.835\n",
      "iter 84: avg train loss=0.0705, time=4.51s\n",
      "VALIDATION: TOP 1: 0.3126, TOP 5: 0.833\n",
      "iter 85: avg train loss=0.0713, time=4.46s\n",
      "VALIDATION: TOP 1: 0.3112, TOP 5: 0.8356\n",
      "iter 86: avg train loss=0.0790, time=4.53s\n",
      "VALIDATION: TOP 1: 0.3126, TOP 5: 0.8346\n",
      "iter 87: avg train loss=0.1369, time=4.45s\n",
      "VALIDATION: TOP 1: 0.3102, TOP 5: 0.838\n",
      "iter 88: avg train loss=0.1259, time=4.42s\n",
      "VALIDATION: TOP 1: 0.31, TOP 5: 0.835\n",
      "iter 89: avg train loss=0.0956, time=4.37s\n",
      "VALIDATION: TOP 1: 0.3074, TOP 5: 0.8374\n",
      "iter 90: avg train loss=0.0847, time=4.34s\n",
      "VALIDATION: TOP 1: 0.3156, TOP 5: 0.8354\n",
      "iter 91: avg train loss=0.0715, time=4.42s\n",
      "VALIDATION: TOP 1: 0.3188, TOP 5: 0.8364\n",
      "iter 92: avg train loss=0.0695, time=4.61s\n",
      "VALIDATION: TOP 1: 0.317, TOP 5: 0.838\n",
      "iter 93: avg train loss=0.0772, time=4.74s\n",
      "VALIDATION: TOP 1: 0.314, TOP 5: 0.8424\n",
      "iter 94: avg train loss=0.1045, time=4.66s\n",
      "VALIDATION: TOP 1: 0.3102, TOP 5: 0.8352\n",
      "iter 95: avg train loss=0.1205, time=4.64s\n",
      "VALIDATION: TOP 1: 0.308, TOP 5: 0.8394\n",
      "iter 96: avg train loss=0.1135, time=4.41s\n",
      "VALIDATION: TOP 1: 0.3108, TOP 5: 0.836\n",
      "iter 97: avg train loss=0.1095, time=4.44s\n",
      "VALIDATION: TOP 1: 0.3074, TOP 5: 0.8326\n",
      "iter 98: avg train loss=0.0896, time=4.43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: TOP 1: 0.3086, TOP 5: 0.8342\n",
      "iter 99: avg train loss=0.0667, time=4.45s\n",
      "VALIDATION: TOP 1: 0.3036, TOP 5: 0.8344\n",
      "TOP 1: 0.304, TOP 5: 0.8346\n",
      "TOP 1: 0.3108, TOP 5: 0.8366\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    RUNNING THE MODEL!!!!!!!!!!\n",
    "\"\"\"\n",
    "top1_val_list, top5_val_list, top1_train_list, top5_train_list, train_loss_list = [],[],[],[],[]\n",
    "try:\n",
    "    for ITER in range(EPOCHS):\n",
    "        # Init variable\n",
    "        random.shuffle(train)\n",
    "        train_loss = 0.0\n",
    "        start = time.time()\n",
    "        updates = 0\n",
    "        \n",
    "        for batch in minibatch(train):\n",
    "            updates += 1\n",
    "            # pad data with zeros\n",
    "            seqs, image_features, idxs, _, lengths = preprocessbatch(batch)\n",
    "            \n",
    "            #reset hidden layer.1\n",
    "            #@todo not certain if we need this\n",
    "            model.hidden = model.init_hidden() \n",
    "            \n",
    "            \n",
    "            # forward pass\n",
    "            scores = model(getLongTensor(np.array([seqs]))[0], getFloatTensor(image_features), getLongTensor(np.array(lengths)))\n",
    "            targets = getLongTensor(np.array([idxs]))\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            output = loss(scores[:, :, 0], targets[0])\n",
    "            train_loss += output.data[0]\n",
    "            \n",
    "            # backward pass\n",
    "            model.zero_grad()\n",
    "            output.backward()\n",
    "            \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "                        \n",
    "            if(updates % 1000 == 0):\n",
    "                print(\"update: {}, train_loss: {}, time {}\".format(updates, train_loss/updates, time.time()-start))\n",
    "        \n",
    "        train_loss_list.append(train_loss/updates)\n",
    "        print(\"iter %r: avg train loss=%.4f, time=%.2fs\" % (ITER, train_loss/updates, time.time()-start))\n",
    "        top1, top5 = evaluate(model, val, show_n_wrong_images=0, show_n_good_images=0)   \n",
    "        top1_val_list.append(top1)\n",
    "        top5_val_list.append(top5)\n",
    "        \n",
    "        print(\"VALIDATION: TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "        top1, top5 = evaluate(model, train[:1000], show_n_wrong_images=0, show_n_good_images=0)  \n",
    "        top1_train_list.append(top1)\n",
    "        top5_train_list.append(top5)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped at ITER: ' + str(ITER))\n",
    "\n",
    "# create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list)\n",
    "top1, top5 = evaluate(model, val, show_n_wrong_images=0, show_n_good_images=0)\n",
    "print(\"TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "\n",
    "\n",
    "write(top1_val_list, \"top1_val\")\n",
    "write(top5_val_list, \"top5_val\")\n",
    "write(top1_train_list, \"top1_train\")\n",
    "write(top5_train_list, \"top5_train\")\n",
    "write(train_loss_list, \"train_loss\")\n",
    "\n",
    "top1, top5 = evaluate(model, test, show_n_wrong_images=0, show_n_good_images=0)\n",
    "print(\"TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "write(top1, \"top1_test\")\n",
    "write(top5, \"top5_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# torch.cuda.clear() \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -6.2118e-02  7.9667e-02 -5.2082e-02  ...   9.5811e-02 -7.9205e-02  1.0630e-01\n",
      " -5.5698e-02  1.7827e-02 -1.3496e-01  ...  -6.1180e-02 -1.2932e-01  1.3219e-01\n",
      " -8.9346e-02 -4.1923e-02 -1.3960e-02  ...  -7.9432e-02 -1.0256e-01  2.4854e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -9.3857e-02 -2.1711e-01 -1.1161e-01  ...   3.1571e-02 -6.1161e-02  3.1064e-01\n",
      " -8.4089e-02 -1.2788e-01 -2.1182e-01  ...  -1.1321e-01 -1.3140e-01  3.4619e-01\n",
      " -5.5830e-02  1.1704e-01  3.4745e-02  ...  -1.6995e-01 -1.2687e-01  2.7499e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.1401e-02  8.0521e-02  9.2011e-02  ...   4.3114e-02 -1.7811e-02  9.4482e-02\n",
      " -7.0157e-02  3.7095e-02  1.0413e-01  ...  -7.8126e-02 -6.2758e-02  2.9297e-01\n",
      " -7.2522e-02  3.9287e-02  1.4407e-01  ...  -1.3843e-01 -4.9256e-02  2.7699e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.2916e-01 -1.3953e-01  3.3196e-02  ...  -1.2510e-01 -1.3220e-01  2.8005e-01\n",
      " -1.2546e-01 -1.1507e-01  1.6058e-02  ...  -1.5962e-01 -1.0901e-01  3.9965e-01\n",
      " -1.8799e-01 -9.8792e-02 -7.8628e-03  ...  -1.5126e-01 -1.1800e-01  3.8994e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -9.8449e-02  4.5697e-02 -1.5560e-01  ...   1.2364e-01 -5.7551e-02  1.3241e-01\n",
      " -7.3923e-02  1.7502e-01 -3.1557e-02  ...   1.1425e-01 -1.1359e-01  1.6412e-01\n",
      " -1.5192e-01  4.9055e-02 -1.1584e-01  ...   2.3614e-02 -9.2926e-02  1.8547e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.5292e-01  1.7005e-01 -1.7480e-01  ...  -3.6591e-02 -1.2024e-01  4.2198e-01\n",
      " -9.3528e-02  1.2826e-01  2.9571e-02  ...  -1.2863e-01 -1.0014e-01  4.7101e-01\n",
      " -9.8236e-02 -7.9045e-02  7.8516e-02  ...  -8.3682e-02 -7.4823e-02  3.7671e-01\n",
      "[torch.FloatTensor of size 3x100x100]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "  -0.0557  0.0178 -0.1350  0.1509  0.0185 -0.0354 -0.1908  0.0845 -0.0612\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0689  0.0930  0.1267  0.2561  0.0711  0.0179 -0.0027  0.1086  0.0312\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.1290  0.1059  0.2612  0.0238 -0.1800 -0.0264  0.0582  0.0716 -0.0789\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.1102 -0.3497  0.0426  0.2428 -0.0417 -0.0080  0.1696  0.1812  0.0774\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0188  0.0982 -0.1218  0.0389 -0.2677 -0.0138 -0.0021  0.1154  0.1478\n",
      "\n",
      "Columns 45 to 53 \n",
      "   0.1140  0.2979  0.2090 -0.0048 -0.3315 -0.0105 -0.0973  0.1566  0.2724\n",
      "\n",
      "Columns 54 to 62 \n",
      "   0.2262  0.3112 -0.0820  0.0692  0.1079 -0.0198 -0.1111  0.1802  0.1305\n",
      "\n",
      "Columns 63 to 71 \n",
      "  -0.1432  0.1808  0.2544  0.1237 -0.0388 -0.0285 -0.1284 -0.0553 -0.1495\n",
      "\n",
      "Columns 72 to 80 \n",
      "   0.0904 -0.0347  0.0563  0.0126 -0.0084 -0.0182 -0.0088 -0.1553 -0.0884\n",
      "\n",
      "Columns 81 to 89 \n",
      "   0.1060 -0.0519 -0.0673 -0.2018  0.0882  0.0541  0.1748 -0.0206 -0.2010\n",
      "\n",
      "Columns 90 to 98 \n",
      "   0.1231  0.2842  0.0319  0.1163  0.1354 -0.2677  0.0582 -0.0612 -0.1293\n",
      "\n",
      "Columns 99 to 99 \n",
      "   0.1322\n",
      "\n",
      "( 1 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "  -0.0725  0.0393  0.1441  0.0785  0.0173 -0.0032 -0.3117  0.1001 -0.0270\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0661  0.0347  0.1997  0.2241  0.1307  0.0802  0.0079  0.0570 -0.0116\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.1718  0.0462  0.2944  0.0033 -0.0470 -0.1454  0.0411 -0.0388 -0.0465\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.1056 -0.2774 -0.0670  0.3417 -0.0475  0.1123  0.3048 -0.0177  0.0905\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.1331  0.1181 -0.0816  0.1845 -0.3656  0.0637  0.0005  0.0017  0.1374\n",
      "\n",
      "Columns 45 to 53 \n",
      "  -0.1728  0.2243  0.2556  0.0371 -0.3289 -0.0942 -0.1266  0.2609  0.2934\n",
      "\n",
      "Columns 54 to 62 \n",
      "   0.2567  0.4008 -0.0965 -0.0088  0.1028  0.0870 -0.1409  0.3135  0.1545\n",
      "\n",
      "Columns 63 to 71 \n",
      "  -0.1369  0.1421  0.2363  0.1396 -0.1073  0.0126 -0.1028 -0.2452 -0.1261\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.0467 -0.0545  0.1151 -0.1205  0.0051 -0.0008  0.0148 -0.0566  0.0529\n",
      "\n",
      "Columns 81 to 89 \n",
      "   0.0214 -0.0328  0.1062 -0.1156  0.1171 -0.1181  0.1608  0.0219 -0.1412\n",
      "\n",
      "Columns 90 to 98 \n",
      "   0.1159  0.2769 -0.0278  0.2200  0.1616 -0.1265  0.0322 -0.1384 -0.0493\n",
      "\n",
      "Columns 99 to 99 \n",
      "   0.2770\n",
      "\n",
      "( 2 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "  -0.0820 -0.0444 -0.0178 -0.0044  0.0450 -0.0835 -0.1493  0.0834 -0.0522\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.1688  0.0931  0.1575  0.4224  0.0107 -0.0445  0.0390  0.1025 -0.0730\n",
      "\n",
      "Columns 18 to 26 \n",
      "   0.0320  0.2156  0.2482 -0.0359 -0.0772 -0.1305  0.0953  0.1464 -0.0258\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.0739 -0.5081 -0.0903  0.4323  0.1032  0.0623  0.4353  0.1884  0.0306\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0419  0.1354 -0.1349 -0.1925 -0.4745  0.0619 -0.0409  0.0931  0.2639\n",
      "\n",
      "Columns 45 to 53 \n",
      "   0.0325  0.2701  0.1208 -0.0828 -0.3414 -0.0626 -0.1314  0.2259  0.2104\n",
      "\n",
      "Columns 54 to 62 \n",
      "   0.1652  0.3244 -0.0711  0.1781  0.1764  0.0369 -0.0893  0.4119  0.1062\n",
      "\n",
      "Columns 63 to 71 \n",
      "  -0.1339  0.1982  0.3348  0.2453 -0.1740 -0.0439 -0.1163 -0.2855 -0.1892\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.1697 -0.0901  0.0411  0.1732 -0.0863 -0.0213  0.0127 -0.0915 -0.0763\n",
      "\n",
      "Columns 81 to 89 \n",
      "   0.1734  0.0887  0.1889 -0.1670  0.0953  0.1308  0.1615  0.0637 -0.1072\n",
      "\n",
      "Columns 90 to 98 \n",
      "  -0.0359  0.2722 -0.1282  0.1699  0.2004 -0.3134 -0.0525 -0.0739 -0.1567\n",
      "\n",
      "Columns 99 to 99 \n",
      "   0.2712\n",
      "[torch.FloatTensor of size 3x1x100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rnn = torch.nn.LSTM(input_size=300, hidden_size=100, batch_first=True)\n",
    "# outputs, h_n = rnn(Variable(torch.rand(75, 100, 300))) # input is of shape [batch_size, sequence, features]\n",
    "# print(outputs)\n",
    "\n",
    "# question_lengths = Variable(torch.LongTensor([2,3,4]))\n",
    "# last_out = torch.gather(outputs, 1, question_lengths.view(-1,1,1).expand(3,1,100)-1) # minus 1 to get from length to index\n",
    "# print(last_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
