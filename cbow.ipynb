{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import h5py\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from heapq import nlargest\n",
    "import dill\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_FEATURES = \"./images/IR_image_features.h5\"\n",
    "IMG_ID = \"./images/IR_img_features2id.json\"\n",
    "\n",
    "TRAIN_HARD = \"./Data/Hard/IR_train_hard.json\"\n",
    "TRAIN_EASY = \"./Data/Easy/IR_train_easy.json\"\n",
    "TEST_HARD = \"./Data/Hard/IR_test_hard.json\"\n",
    "TEST_EASY = \"./Data/Easy/IR_test_easy.json\"\n",
    "VAL_HARD = \"./Data/Hard/IR_val_hard.json\"\n",
    "VAL_EASY = \"./Data/Easy/IR_val_easy.json\"\n",
    "\n",
    "IMGID2IMGINFO = \"./Data/imgid2imginfo.json\"\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "CAPTION_DICT = {}\n",
    "CURRENT_MODEL_NAME = \"CBOW_PRE_HARD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write(x, name):\n",
    "    import pickle\n",
    "    file_name = './results/' + CURRENT_MODEL_NAME + '/' + name + '.npy'\n",
    "    np.save(file_name, np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GET features from images\n",
    "with open(\"./images/IR_img_features2id.json\", 'r') as f:\n",
    "    visual_feat_mapping = json.load(f)['IR_imgid2id']\n",
    "f.close()\n",
    "\n",
    "img_features = np.asarray( h5py.File(\"./images/IR_image_features.h5\", 'r')['img_features'])\n",
    "\n",
    "def get_feature_from_id(img_id):\n",
    "    h5_id = visual_feat_mapping[str(img_id)]\n",
    "    return img_features[h5_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-b0ba592f3fd4>\", line 43, in show_img_from_id\n",
      "    fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 30)\n",
      "  File \"/Users/romeo/anaconda2/envs/nlp/lib/python3.6/site-packages/PIL/ImageFont.py\", line 259, in truetype\n",
      "    return FreeTypeFont(font, size, index, encoding, layout_engine)\n",
      "  File \"/Users/romeo/anaconda2/envs/nlp/lib/python3.6/site-packages/PIL/ImageFont.py\", line 143, in __init__\n",
      "    self.font = core.getfont(font, size, index, encoding, layout_engine=layout_engine)\n",
      "OSError: cannot open resource\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Helper function to show an image, from a image id \"\"\"\n",
    "#source: https://stackoverflow.com/questions/34255938/is-there-a-way-to-specify-the-width-of-a-rectangle-in-pil\n",
    "def draw_rectangle(draw, coordinates, color, width=100):\n",
    "    for i in range(width):\n",
    "        rect_start = (coordinates[0][0] - i, coordinates[0][1] - i)\n",
    "        rect_end = (coordinates[1][0] + i, coordinates[1][1] + i)\n",
    "        draw.rectangle((rect_start, rect_end), outline = color)\n",
    "\n",
    "def show_img_from_id(img_ids, target_id = -1):\n",
    "    \n",
    "    try:\n",
    "        with open(IMGID2IMGINFO, 'r') as f:\n",
    "            imgid2info = json.load(f)\n",
    "\n",
    "        response = requests.get(imgid2info[str(img_ids[0])]['coco_url'])\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        imgs = [img, img]\n",
    "        width, height = img.size\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        line_width = 30\n",
    "        draw.rectangle(((0, 0), (width*2, height*2)), fill=\"white\")\n",
    "        for img_id in img_ids:\n",
    "            response = requests.get(imgid2info[str(img_id)]['coco_url'])\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            if(img_id == target_id):\n",
    "                width, height = img.size\n",
    "                draw = ImageDraw.Draw(img)\n",
    "                line_width = 30\n",
    "                draw_rectangle(draw, coordinates=((line_width, line_width), (width - line_width, height - line_width)), color=\"green\", width=line_width)\n",
    "            imgs.append(img)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[-1][1]\n",
    "        imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "        # save that beautiful picture\n",
    "        imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "        width, height = imgs_comb.size\n",
    "        draw = ImageDraw.Draw(imgs_comb)\n",
    "        if(target_id != -1):\n",
    "            fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 30)\n",
    "            draw.multiline_text((10, 10), CAPTION_DICT[target_id].replace(\"?\", \"?\") ,(0,0,0), font=fnt)\n",
    "\n",
    "        files = \"[\"+str(target_id)+\"]_\"\n",
    "        files += '_'.join(map(str, img_ids))\n",
    "        if(img_ids[0] == target_id):\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/correct/top1/'\n",
    "        elif(img_ids[1] == target_id or img_ids[2] == target_id or img_ids[3] == target_id or img_ids[4] == target_id):\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/correct/top5/'  \n",
    "        else:\n",
    "            file_name = './results/' + CURRENT_MODEL_NAME + '/wrong/' \n",
    "        imgs_comb.save( file_name + files + '.jpg' )\n",
    "    except:\n",
    "        import traceback\n",
    "        print( traceback.format_exc())\n",
    "        pass\n",
    "    \n",
    "show_img_from_id([378466, 378466, 378466, 378466], 378466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess a sentence\n",
    "\"\"\"\n",
    "def preprocess(sentence, stemmer, stop):\n",
    "    low_sent = sentence.lower()\n",
    "    # Possibility to tokenize entire dataset and put in counter to filter out\n",
    "    # infrequent/frequent words\n",
    "    tok_sent = word_tokenize(low_sent)\n",
    "    stop_stem_sent = [stemmer.stem(i) for i in tok_sent if i not in stop]\n",
    "    return stop_stem_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert Samples\n",
    "\"\"\"\n",
    "\n",
    "def get_dialog_caption_targets_from_sample(sample):\n",
    "    dialog = ''\n",
    "    caption = sample['caption']\n",
    "    targets = []\n",
    "    targetidx = sample['target']\n",
    "   \n",
    "    dialog_text = ''\n",
    "    for d in sample['dialog']:\n",
    "        dialog += ' ' + d[0]\n",
    "        dialog_text += ' ' + d[0] + '\\n'\n",
    "\n",
    "    for img in sample['img_list']:\n",
    "        targets.append(img)\n",
    "    \n",
    "    CAPTION_DICT[targets[targetidx]] = dialog_text + \"  \\n \" + caption\n",
    "    return dialog, caption, targets, targetidx\n",
    "\n",
    "Sample = namedtuple(\"Sample\", [\"words\", \"images\", \"target\"])\n",
    "\n",
    "\"\"\"\n",
    " For every Sample we retrieve the sentences and the img_ids, and the correct target_id. \n",
    "\"\"\"\n",
    "def read_dataset(filename, stemmer, stopwords):\n",
    "    with open(filename, \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "    f.close()\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        if(idx % 10000 == 0):\n",
    "            print(idx)\n",
    "        dialog, caption, targets, targetidx = get_dialog_caption_targets_from_sample(dataset[\n",
    "                                                                                     str(sample)])\n",
    "        sentences = preprocess(dialog + ' ' + caption, stemmer, stopwords)\n",
    "        yield Sample(words=[w2i[x] for x in sentences], images=targets, target=targetidx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "UNK = w2i[\"<UNK>\"]\n",
    "PAD = w2i[\"<PAD>\"]\n",
    "\n",
    "# Do this super one time \n",
    "import nltk\n",
    "# nltk.download(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop = stopwords.words('english') + list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#read the datasets and use w2i (only do this once)\n",
    "train = list(read_dataset(TRAIN_HARD, stemmer, stop))\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "val = list(read_dataset(VAL_HARD, stemmer, stop))\n",
    "test = list(read_dataset(TEST_HARD, stemmer, stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CLASS LSTM \n",
    "\"\"\"\n",
    "\n",
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, img_feat_dim, hidden_dim_mlp, output_dim, batch_size):\n",
    "        super(ClassificationNN,self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=PAD)\n",
    "        self.batch_size = batch_size\n",
    "        self.linear1 = nn.Linear(embedding_size+img_feat_dim,hidden_dim_mlp)\n",
    "        self.linear2 = nn.Linear(hidden_dim_mlp,output_dim)\n",
    "\n",
    "    def forward(self, sentence, image_feat):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = torch.sum(embeds, 1)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = x.repeat(1,10,1)\n",
    "        lin1 = F.sigmoid(self.linear1(torch.cat((x, image_feat),2)))\n",
    "        lin2 = self.linear2(lin1)\n",
    "        return lin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:  100 LEARNING_RATE:  0.001\n",
      "\n",
      "ClassificationNN (\n",
      "  (word_embeddings): Embedding(15456, 50, padding_idx=1)\n",
      "  (linear1): Linear (2098 -> 45)\n",
      "  (linear2): Linear (45 -> 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# INIT MODEL AND INIT OPTIMIZER\n",
    "print(\"Batch_size: \", BATCH_SIZE, \"LEARNING_RATE: \",LEARNING_RATE)\n",
    "print()\n",
    "\n",
    "model = ClassificationNN(nwords, 50, 2048, 45, 1, BATCH_SIZE)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "print(model)\n",
    "\n",
    "#@TODO we can use a adaptive learnrate for adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HELPER FUNCTIONS\n",
    "\"\"\"\n",
    "def preprocessbatch(batch):\n",
    "    \"\"\" Add zero-padding to a batch. \"\"\"\n",
    "    seqs = [sample.words for sample in batch]\n",
    "    max_length = max(map(len, seqs))\n",
    "    seqs = [seq + [PAD] * (max_length - len(seq)) for seq in seqs]\n",
    "\n",
    "    ims = np.array([[get_feature_from_id(img_id) for img_id in sample.images] for sample in batch])\n",
    "\n",
    "    idxs = [sample.target for sample in batch]\n",
    "    \n",
    "    image_ids = [sample.images for sample in batch]\n",
    "\n",
    "    return seqs, ims, idxs, image_ids\n",
    "\n",
    "def minibatch(data, batch_size=BATCH_SIZE):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i+batch_size]\n",
    "\n",
    "def getLongTensor(x):\n",
    "    tensor = torch.cuda.LongTensor(x) if CUDA else torch.LongTensor(x)\n",
    "    return Variable(tensor)\n",
    "\n",
    "\n",
    "def getFloatTensor(x):\n",
    "    tensor = torch.cuda.FloatTensor(torch.from_numpy(\n",
    "        x).cuda()) if CUDA else torch.FloatTensor(x)\n",
    "    return Variable(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "FUNCTIONS TO SEE HOW GOOD OUR MODEL DID\n",
    "\n",
    "@TODO: Not fast \n",
    "@TODO: top 5 currently not implemented\n",
    "\"\"\"\n",
    "def evaluate(model, data, show_n_wrong_images  = 0, show_n_good_images=0):\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    \n",
    "    counter_good = 0\n",
    "    counter_wrong = 0\n",
    "    for batch in minibatch(data):\n",
    "        seqs, image_features, idxs, image_ids = preprocessbatch(batch)\n",
    "        scores = model(getLongTensor(seqs), getFloatTensor(image_features))\n",
    "        targets = getLongTensor([idxs])\n",
    "        _, predictions = torch.max(scores[:, :,0].data, 1)\n",
    "        \n",
    "#         print(targets.data.cpu().numpy().shape)\n",
    "#         top1 += torch.eq(predictions, targets[0]).sum().data[0]\n",
    "        \n",
    "        _, top5_predictions = torch.topk(scores[:, :,0].data, 5)\n",
    "        _, top10_predictions = torch.topk(scores[:, :,0].data, 10)\n",
    "        for i in range(len(top5_predictions)):\n",
    "            if((targets[0][i].data.cpu().numpy() if CUDA else targets[0][i].data.numpy()) in (top5_predictions[i].cpu().numpy() if CUDA else top5_predictions[i].numpy())):\n",
    "                idx, = np.where((targets[0][i].data.cpu().numpy() if CUDA else targets[0][i].data.numpy()) == (top5_predictions[i].cpu().numpy() if CUDA else top5_predictions[i].numpy()))\n",
    "                if idx == 0:\n",
    "                    top1 += 1\n",
    "                \n",
    "                top5 += 1\n",
    "                \n",
    "                #Show the images Good examples\n",
    "                if counter_good < show_n_good_images:\n",
    "                    image_list = list(np.array(image_ids[i])[(top10_predictions[i].cpu().numpy() if CUDA else top10_predictions[i].numpy())])\n",
    "                    show_img_from_id(image_list, target_id = int(np.array(image_ids[i])[idxs[i]]))\n",
    "                    counter_good += 1\n",
    "            else: \n",
    "                #Show the images Bad examples\n",
    "                if counter_wrong < show_n_wrong_images:\n",
    "                    image_list = list(np.array(image_ids[i])[(top10_predictions[i].cpu().numpy() if CUDA else top10_predictions[i].numpy())])\n",
    "                    show_img_from_id(image_list, target_id = int(np.array(image_ids[i])[idxs[i]]))\n",
    "                    counter_wrong += 1\n",
    "                \n",
    "           \n",
    "    return top1/len(data), top5/len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cd7b6b8cf394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop1_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mITER\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Init variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    RUNNING THE MODEL!!!!!!!!!!\n",
    "\"\"\"\n",
    "top1_val_list, top5_val_list, top1_train_list, top5_train_list, train_loss_list = [],[],[],[],[]\n",
    "try:\n",
    "    for ITER in range(EPOCHS):\n",
    "        # Init variable\n",
    "        random.shuffle(train)\n",
    "        train_loss = 0.0\n",
    "        start = time.time()\n",
    "        updates = 0\n",
    "        \n",
    "        for batch in minibatch(train):\n",
    "            updates += 1\n",
    "            \n",
    "            # pad data with zeros\n",
    "            seqs, image_features, idxs, _ = preprocessbatch(batch)\n",
    "            print(image_features.shape)\n",
    "            #reset hidden layer.1\n",
    "            #@todo not certain if we need this\n",
    "            #  model.hidden = model.init_hidden() \n",
    "            \n",
    "            \n",
    "            # forward pass\n",
    "            scores = model(getLongTensor([seqs])[0], getFloatTensor(image_features))\n",
    "            targets = getLongTensor([idxs])\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            output = loss(scores[:, :, 0], targets[0])\n",
    "            train_loss += output.data[0]\n",
    "            \n",
    "            # backward pass\n",
    "            model.zero_grad()\n",
    "            output.backward()\n",
    "            \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            if(updates % 1000 == 0):\n",
    "                print(\"update: {}, train_loss: {}, time {}\".format(updates, train_loss/updates, time.time()-start))\n",
    "        \n",
    "        train_loss_list.append(train_loss/updates)\n",
    "        print(\"iter %r: avg train loss=%.4f, time=%.2fs\" % (ITER, train_loss/updates, time.time()-start))\n",
    "        top1, top5 = evaluate(model, val, show_n_wrong_images=0, show_n_good_images=0)   \n",
    "        top1_val_list.append(top1)\n",
    "        top5_val_list.append(top5)\n",
    "        \n",
    "        print(\"VALIDATION: TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "        top1, top5 = evaluate(model, train, show_n_wrong_images=0, show_n_good_images=0)  \n",
    "        top1_train_list.append(top1)\n",
    "        top5_train_list.append(top5)\n",
    "        \n",
    "        print(\"TRAIN: TOP 1: {}, TOP 5: {} \\n\".format(top1, top5))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped at ITER: ' + str(ITER))\n",
    "\n",
    "\n",
    "# create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list)\n",
    "top1, top5 = evaluate(model, val, show_n_wrong_images=0, show_n_good_images=0)\n",
    "print(\"TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "\n",
    "\n",
    "write(top1_val_list, \"top1_val\")\n",
    "write(top5_val_list, \"top5_val\")\n",
    "write(top1_train_list, \"top1_train\")\n",
    "write(top5_train_list, \"top5_train\")\n",
    "write(train_loss_list, \"train_loss\")\n",
    "\n",
    "top1, top5 = evaluate(model, test, show_n_wrong_images=0, show_n_good_images=0)\n",
    "print(\"TOP 1: {}, TOP 5: {}\".format(top1, top5))\n",
    "write(top1, \"top1_test\")\n",
    "write(top5, \"top5_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    \n",
    "    ax.plot(top5_val_list, label='top5 validation', c='darkred')\n",
    "    ax.plot(top5_train_list, label='top5 train', c='royalblue')\n",
    "    \n",
    "    ax.plot(top1_val_list, linestyle=':', label='top1 validation', c='darkred')\n",
    "    ax.plot(top1_train_list, linestyle=':', label='top1 train', c='royalblue')\n",
    "    \n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.75, box.height])\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title('Learning curve of CBOW EASY')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.savefig('./results/' + CURRENT_MODEL_NAME + '/accuracy1.png')\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-28dc39610093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_learning_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop1_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_train_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c347d2176e67>\u001b[0m in \u001b[0;36mcreate_learning_curves\u001b[0;34m(top1_val_list, top5_val_list, top1_train_list, top5_train_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_learning_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop1_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_train_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at torch/csrc/cuda/Module.cpp:321",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-651f61c71ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/nlp/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mallocator\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthose\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     `nvidia-smi`.\"\"\"\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at torch/csrc/cuda/Module.cpp:321"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1: 0.387, TOP 5: 0.8818\n"
     ]
    }
   ],
   "source": [
    "# create_learning_curves(top1_val_list, top5_val_list, top1_train_list, top5_train_list)\n",
    "top1, top5 = evaluate(model, val, show_n_wrong_images=40, show_n_good_images=40)\n",
    "print(\"TOP 1: {}, TOP 5: {}\".format(top1, top5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
